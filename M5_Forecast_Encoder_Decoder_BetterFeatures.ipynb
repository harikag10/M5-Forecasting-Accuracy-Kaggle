{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5_Forecast_Encoder_Decoder_BetterFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h66t4-AB6Pnfn0lV3eGVH4L64a3VmH3_",
      "authorship_tag": "ABX9TyNm7Tos/TuOH2cWIZ+xlK3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikyath/M5-Forecasting-Accuracy-Kaggle/blob/master/M5_Forecast_Encoder_Decoder_BetterFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7HulDDx1YG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bninEuK71iI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My\\ Drive/Data\\ Science\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szYw7quF18Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers import RepeatVector,TimeDistributed\n",
        "from numpy import array\n",
        "from keras.models import Sequential, load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leYyDvlb1rfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJrSUTMy12Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(PATH):\n",
        "    print('Reading files...')\n",
        "    calendar = pd.read_csv(f'{PATH}/calendar.csv')\n",
        "    calendar = reduce_mem_usage(calendar)\n",
        "    print('Calendar has {} rows and {} columns'.format(calendar.shape[0], calendar.shape[1]))\n",
        "    sell_prices = pd.read_csv(f'{PATH}/sell_prices.csv')\n",
        "    sell_prices = reduce_mem_usage(sell_prices)\n",
        "    print('Sell prices has {} rows and {} columns'.format(sell_prices.shape[0], sell_prices.shape[1]))\n",
        "    sales_train_validation = pd.read_csv(f'{PATH}/sales_train_validation.csv')\n",
        "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation.shape[0], sales_train_validation.shape[1]))\n",
        "    submission = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
        "    return calendar, sell_prices, sales_train_validation, submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yVhliYi14K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar, selling_prices, sales, submission = read_data(\"/content/drive/My Drive/Data Science\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv6XN8L2-gSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales = pd.read_csv('sales_train_validation.csv')\n",
        "calendar = pd.read_csv('calendar.csv')\n",
        "selling_prices = pd.read_csv('sell_prices.csv')\n",
        "submission_file = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkvwoNQA1_xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd-85T1n2RMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVW6FL602UT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "days = range(1, 1970)\n",
        "time_series_columns = [f'd_{i}' for i in days]\n",
        "transfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T, index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'], columns= time_series_columns)\n",
        "transfer_cal = transfer_cal.fillna(0)\n",
        "event_name_1_se = transfer_cal.loc['event_name_1'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\n",
        "event_name_2_se = transfer_cal.loc['event_name_2'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "austjD4S3TGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_cal.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v64yVg03ZgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(data):\n",
        "    \n",
        "    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
        "    for feature in nan_features:\n",
        "        data[feature].fillna('unknown', inplace = True)\n",
        "        \n",
        "    cat = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','month','wday']\n",
        "    for feature in cat:\n",
        "        encoder = preprocessing.LabelEncoder()\n",
        "        data[feature] = encoder.fit_transform(data[feature])\n",
        "\n",
        "    # # week day\n",
        "    # week_period = 7 / (2 * np.pi)\n",
        "    # dow_norm = data[\"wday\"].values / week_period\n",
        "    # wday_cos = pd.DataFrame(np.cos(dow_norm))\n",
        "    # wday_sin = pd.DataFrame(np.sin(dow_norm))\n",
        "    \n",
        "    \n",
        "    \n",
        "    # # month\n",
        "    # month_period = 12 / (2 * np.pi)\n",
        "    # dow_norm = data[\"month\"].values / month_period\n",
        "    # month_cos = pd.DataFrame(np.cos(dow_norm))\n",
        "    # month_sin = pd.DataFrame(np.sin(dow_norm))\n",
        "    # # print(month_sin)\n",
        "\n",
        "    # #print(df[\"date\"])\n",
        "\n",
        "    # # day\n",
        "    # day_period = 31 / (2 * np.pi)\n",
        "    # dow_norm = data[\"date\"].dt.day / day_period\n",
        "    # day_cos = pd.DataFrame(np.cos(dow_norm))\n",
        "    # day_sin = pd.DataFrame(np.sin(dow_norm))\n",
        "    # print(day_sin)\n",
        "    \n",
        "    data['wday_cos'] = np.cos(data['wday']/(7/(2*np.pi)))\n",
        "    data['wday_sin'] = np.sin(data['wday']/(7/(2*np.pi)))\n",
        "\n",
        "    data['month_cos'] = np.cos(data['month']/(12/(2*np.pi)))\n",
        "    data['month_sin'] = np.sin(data['month']/(12/(2*np.pi)))\n",
        "\n",
        "    data['day_cos'] = np.cos(data[\"date\"].dt.day/(31/(2*np.pi)))\n",
        "    data['day_sin'] = np.sin(data[\"date\"].dt.day/(31/(2*np.pi)))\n",
        "\n",
        "\n",
        "    # # month\n",
        "    # month = pd.get_dummies(data[\"month\"], drop_first=False, prefix=\"month\")\n",
        "    # month = (month - month.mean()) / month.std()\n",
        "\n",
        "    # day\n",
        "    # day = pd.get_dummies(data[\"date\"].dt.day, drop_first=False, prefix=\"date\")\n",
        "    # day = (day - day.mean()) / day.std()\n",
        "\n",
        "    # data = pd.merge(data,day_cos, how=\"left\",left_on=date, left_index=True, right_index=True,)\n",
        "    # data = pd.merge(data,day_sin, how=\"left\", left_on=date,left_index=True, right_index=True)\n",
        "    # data = pd.merge(data,wday_cos, how=\"left\",left_on=wday ,left_index=True, right_index=True)\n",
        "    # data = pd.merge(data,wday_sin, how=\"left\", left_on=wday,left_index=True, right_index=True)\n",
        "    # data = pd.merge(data,month_cos, how=\"left\", left_on=month,left_index=True, right_index=True)\n",
        "    # data = pd.merge(data,month_sin, how=\"left\", left_on=month,left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQeOdBJJIdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LlOGFQD326L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar['date'] = pd.to_datetime(calendar['date'])\n",
        "calendar = calendar[calendar['date']>= '2016-1-27']  #reduce memory\n",
        "calendar= transform(calendar)\n",
        "# Attempts to convert events into time series data.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsVjQciyJI3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB6DG_iIJFoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','day_cos','day_sin','wday_cos','wday_sin','month_cos','month_sin']].values.T,\n",
        "                            index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI','day_cos','day_sin','wday_cos','wday_sin','month_cos','month_sin'])\n",
        "transfer_cal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi1wvRtC37Bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLWeHdI4Rbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtoovNd67J4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_fea = calendar[['wm_yr_wk','date']].merge(selling_prices, on = ['wm_yr_wk'], how = 'left')\n",
        "price_fea['id'] = price_fea['item_id']+'_'+price_fea['store_id']+'_validation'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FctUs3hP7br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_fea.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0beDz8e-aKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = price_fea.pivot('id','date','sell_price')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKGOLpu_M8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgs-Z2v7Kar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_fea.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7EW7SWf7pjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_df = sales.merge(df,on=['id'],how= 'left').iloc[:,-145:]\n",
        "price_df.index = sales.id\n",
        "price_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRuqFJcV74Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_cal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2GVCYhV_dXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_cal.loc['event_name_1'][-(100+28):-(28)].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ0UOe17APsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "days = range(1, 1913 + 1)\n",
        "time_series_columns = [f'd_{i}' for i in days]\n",
        "time_series_data = sales[time_series_columns]  #Get time series data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H5wRebIA-c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_series_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZzutmxw_iUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []   #build a data with two features(salse and event1)\n",
        "for i in tqdm(range(time_series_data.shape[0])):\n",
        "    X.append([list(t) for t in zip(transfer_cal.loc['event_name_1'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['event_type_1'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['event_name_2'][-(100+28):-(28)],     \n",
        "                                   transfer_cal.loc['event_type_2'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['snap_CA'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['snap_TX'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['snap_WI'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['day_sin'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['day_cos'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['wday_sin'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['wday_cos'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['month_sin'][-(100+28):-(28)],\n",
        "                                   transfer_cal.loc['month_cos'][-(100+28):-(28)],\n",
        "                                   price_df.iloc[i][-(100+28):-(28)],\n",
        "                                   time_series_data.iloc[i][-100:])]) \n",
        "\n",
        "X = np.asarray(X, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwyR4mVT_r-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL7kXJh8AW66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Normalize(list):\n",
        "    list = np.array(list)\n",
        "    low, high = np.percentile(list, [0, 100])\n",
        "    delta = high - low\n",
        "    if delta != 0:\n",
        "        for i in range(0, len(list)):\n",
        "            list[i] = (list[i]-low)/delta\n",
        "    return  list,low,high\n",
        "\n",
        "def FNoramlize(list,low,high):\n",
        "    delta = high - low\n",
        "    if delta != 0:\n",
        "        for i in range(0, len(list)):\n",
        "            list[i] = list[i]*delta + low\n",
        "    return list\n",
        "\n",
        "def Normalize2(list,low,high):\n",
        "    list = np.array(list)\n",
        "    delta = high - low\n",
        "    if delta != 0:\n",
        "        for i in range(0, len(list)):\n",
        "            list[i] = (list[i]-low)/delta\n",
        "    return  list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szc2-AsyAY7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7)\n",
        "\n",
        " ## I only use the last 56 days for train_data.\n",
        "if __name__ == '__main__':\n",
        "    n_steps = 28\n",
        "    train_n,train_low,train_high = Normalize(X[:,-(n_steps*4):,:])\n",
        "    X_train = train_n[:,-28*4:-28,:]\n",
        "    print(X_train.shape)\n",
        "    y = train_n[:,-28:,14]  #     \n",
        "    # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "    n_features = 15\n",
        "    n_out_seq_length =28\n",
        "    num_y = 1\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
        "    y = y.reshape((y.shape[0], y.shape[1], 1))\n",
        "    print(X_train.shape)\n",
        "    # define model\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    \n",
        "    model.add(LSTM(128, activation='tanh', input_shape=(72, n_features),return_sequences=True))\n",
        "    model.add(LSTM(64, activation='tanh',return_sequences=False))\n",
        "    model.add(RepeatVector(n_out_seq_length))\n",
        "    model.add(LSTM(32, activation='tanh',return_sequences=True))\n",
        "    model.add(LSTM(16, activation='tanh',return_sequences=True))\n",
        "    model.add(Dropout(0.1))  \n",
        "    model.add(TimeDistributed(Dense(num_y)))   # num_y means the shape of y,in some problem(like translate), it can be many.\n",
        "                                                #In that case, you should set the  activation= 'softmax'\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    # demonstrate prediction\n",
        "    model.fit(X_train, y, epochs=20, batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0n9-1rLAcJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input = array(X_train[:,-72:])\n",
        "x_input = x_input.reshape((30490, 72, n_features))\n",
        "print(x_input.shape)\n",
        "#x_input = Normalize2(x_input,train_low,train_high)\n",
        "yhat = model.predict(x_input[:,-72:], verbose=0)\n",
        "x_input=np.concatenate((x_input[:,:,14].reshape(x_input.shape[0],x_input.shape[1]),yhat.astype(np.float32).reshape(x_input.shape[0],x_input.shape[1]-44)),axis=1).reshape((x_input.shape[0],x_input.shape[1]+28,1));\n",
        "#print(yhat)\n",
        "print(x_input.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZds6yAiAe7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input = FNoramlize(x_input,train_low,train_high)\n",
        "# x_input = np.rint(x_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgzrWI-jAhH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forecast = pd.DataFrame(x_input.reshape(x_input.shape[0],x_input.shape[1])).iloc[:,-28:]\n",
        "forecast.columns = [f'F{i}' for i in range(1, forecast.shape[1] + 1)]\n",
        "forecast[forecast < 0] =0\n",
        "forecast.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRg3zifGAisg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_ids = sales['id'].values\n",
        "evaluation_ids = [i.replace('validation', 'evaluation') for i in validation_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1yT62xIAkn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = np.concatenate([validation_ids, evaluation_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irD7RCb7Amyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pd.DataFrame(ids, columns=['id'])\n",
        "forecast = pd.concat([forecast]*2).reset_index(drop=True)\n",
        "predictions = pd.concat([predictions, forecast], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLzCW2dcApB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions.to_csv('submission.csv', index=False)  #Generate the csv file."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}